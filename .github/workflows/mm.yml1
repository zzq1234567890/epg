name: æå–é›»è¦–å°åç¨±å’Œç”Ÿæˆåˆ†æå ±å‘Šçµ±è¨ˆè¡¨æ¸¬è©¦
on:
  schedule:
    - cron: '45 */6 * * *'
  workflow_dispatch:

jobs:
  extract:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout current repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download XML files
        run: |
          curl -L --retry 3 --max-time 10 -o twepg.xml https://raw.githubusercontent.com/zzq1234567890/epg/main/twepg.xml
          curl -L --retry 3 --max-time 10 -o swepg.xml https://raw.githubusercontent.com/zzq1234567890/epg/main/swepg.xml
          [ -s twepg.xml ] || { echo "twepg.xml ä¸ºç©º"; exit 1; }
          [ -s swepg.xml ] || { echo "swepg.xml ä¸ºç©º"; exit 1; }

      - name: Extract channel names, analyze, and update README
        run: |
          python <<'EOF'
          import xml.etree.ElementTree as ET
          import json
          from datetime import datetime
          import re
          import os

          def analyze_epg_data(xml_file):
              try:
                  tree = ET.parse(xml_file)
                  root = tree.getroot()
                  ns = {}
                  if root.tag.startswith('{'):
                      ns_uri = root.tag.split('}')[0][1:]
                      ns = {'ns': ns_uri}
                  
                  channels_info = {}
                  channel_xpath = 'ns:channel' if ns else 'channel'
                  
                  # 1. æ”¶é›†é »é“ä¿¡æ¯
                  for channel in root.findall(channel_xpath, ns):
                      channel_id = channel.get('id')
                      if not channel_id: continue
                      
                      name = channel.get('display-name')
                      if not name:
                          name_elem = channel.find('ns:display-name' if ns else 'display-name', ns)
                          name = name_elem.text.strip() if name_elem is not None and name_elem.text else None
                      
                      name = name.strip() if name else channel_id
                      channels_info[channel_id] = {
                          'name': name,
                          'program_count': 0,
                          'start_times': [],
                          'end_times': []
                      }

                  # 2. çµ±è¨ˆç¯€ç›®
                  programme_xpath = 'ns:programme' if ns else 'programme'
                  for programme in root.findall(programme_xpath, ns):
                      channel_id = programme.get('channel')
                      if channel_id not in channels_info: continue
                          
                      channels_info[channel_id]['program_count'] += 1
                      start = programme.get('start')
                      stop = programme.get('stop')
                      
                      if start: channels_info[channel_id]['start_times'].append(re.sub(r'\s+[+-]\d{4}$', '', start))
                      if stop: channels_info[channel_id]['end_times'].append(re.sub(r'\s+[+-]\d{4}$', '', stop))

                  # 3. æ•´ç†çµæœ
                  result = []
                  for channel_id, info in channels_info.items():
                      time_range = "ç„¡æ•¸æ“š"
                      duration_days = 0
                      epg_status = "â–¡"
                      
                      if info['start_times'] and info['end_times']:
                          try:
                              sorted_starts = sorted(info['start_times'])
                              sorted_ends = sorted(info['end_times'])
                              start_dt = datetime.strptime(sorted_starts[0], '%Y%m%d%H%M%S')
                              end_dt = datetime.strptime(sorted_ends[-1], '%Y%m%d%H%M%S')
                              
                              # è¨ˆç®—å¤©æ•¸
                              delta = end_dt - start_dt
                              duration_days = delta.days + (1 if delta.seconds > 0 else 0)
                              
                              time_range = f"{start_dt.strftime('%m-%d %H:%M')} ~ {end_dt.strftime('%m-%d %H:%M')}"
                          except:
                              time_range = "æ ¼å¼ç•°å¸¸"

                      if info['program_count'] > 0: epg_status = "â– "

                      result.append({
                          'channel_id': channel_id,
                          'channel_name': info['name'],
                          'program_count': info['program_count'],
                          'duration_days': duration_days,
                          'time_range': time_range,
                          'epg_status': epg_status
                      })
                  
                  result.sort(key=lambda x: x['channel_name'].lower())
                  return result
              except Exception as e:
                  print(f"âŒ è§£æ {xml_file} å‡ºé”™: {e}")
                  return []

          print("æ­£åœ¨åˆ†æ EPG æ•¸æ“š...")
          tw_data = analyze_epg_data('twepg.xml')
          sw_data = analyze_epg_data('swepg.xml')

          # --- ç”Ÿæˆ JSON æ–‡ä»¶ (ä¿æŒåŸæœ‰åŠŸèƒ½) ---
          def generate_files(data, prefix):
              table_data = {
                  'title': f'{prefix}åˆ—è¡¨',
                  'headers': ['é¢‘é“ID', 'é¢‘é“åç§°', 'èŠ‚ç›®æ•°é‡', 'å¤©æ•°', 'æ—¶é—´èŒƒå›´', 'çŠ¶æ€'],
                  'data': [[c['channel_id'], c['channel_name'], c['program_count'], c['duration_days'], c['time_range'], c['epg_status']] for c in data]
              }
              with open(f'{prefix}_channels_table.json', 'w', encoding='utf-8') as f:
                  json.dump(table_data, f, ensure_ascii=False, indent=2)

          generate_files(tw_data, 'traditional')
          generate_files(sw_data, 'simplified')

          # --- ç”Ÿæˆ README.md (æ–°å¢åŠŸèƒ½) ---
          def generate_readme():
              current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
              md_content = f"# ğŸ“º EPG é›»å­ç¯€ç›®è¡¨ç‹€æ…‹å ±å‘Š\n\n"
              md_content += f"> æœ€å¾Œæ›´æ–°æ™‚é–“: **{current_time}**\n\n"
              
              md_content += "## ğŸ“Š çµ±è¨ˆæ‘˜è¦\n"
              md_content += f"- **ç¹é«”é »é“æ•¸**: {len(tw_data)} (ç¯€ç›®ç¸½æ•¸: {sum(x['program_count'] for x in tw_data)})\n"
              md_content += f"- **ç°¡é«”é »é“æ•¸**: {len(sw_data)} (ç¯€ç›®ç¸½æ•¸: {sum(x['program_count'] for x in sw_data)})\n\n"

              for title, data in [("ğŸ‡¹ğŸ‡¼ ç¹é«”é »é“åˆ—è¡¨", tw_data), ("ğŸ‡¨ğŸ‡³ ç°¡é«”é »é“åˆ—è¡¨", sw_data)]:
                  md_content += f"## {title}\n\n"
                  md_content += "| é »é“åç¨± | ç¯€ç›®æ•¸é‡ | è¦†è“‹å¤©æ•¸ | æ™‚é–“ç¯„åœ | ç‹€æ…‹ |\n"
                  md_content += "| :--- | :---: | :---: | :--- | :---: |\n"
                  
                  for item in data:
                      status_icon = "âœ…" if item['epg_status'] == "â– " else "âš ï¸"
                      # å¦‚æœç¯€ç›®æ•¸ç‚º0ï¼Œé¡¯ç¤ºç´…è‰²è­¦å‘Š
                      count_display = item['program_count'] if item['program_count'] > 0 else "**0**"
                      
                      row = f"| {item['channel_name']} | {count_display} | {item['duration_days']} å¤© | {item['time_range']} | {status_icon} |\n"
                      md_content += row
                  md_content += "\n"
              
              with open('README.md', 'w', encoding='utf-8') as f:
                  f.write(md_content)
              print("âœ… README.md å·²æ›´æ–°")

          generate_readme()
          EOF

      - name: Extract channel names (ä¿æŒé¡ºåº)
        run: |
          python <<'EOF'
          import xml.etree.ElementTree as ET
          def extract(xml, out):
              try:
                  tree = ET.parse(xml)
                  root = tree.getroot()
                  ns = {'ns': root.tag.split('}')[0][1:]} if root.tag.startswith('{') else {}
                  seen = set()
                  lines = []
                  path = 'ns:channel' if ns else 'channel'
                  for c in root.findall(path, ns):
                      n = c.get('display-name')
                      if not n:
                          ne = c.find('ns:display-name' if ns else 'display-name', ns)
                          n = ne.text.strip() if ne and ne.text else c.get('id')
                      if n and n not in seen:
                          seen.add(n); lines.append(n)
                  with open(out, 'w', encoding='utf-8') as f: f.write('\n'.join(lines))
              except: pass
          extract('twepg.xml', 'ç¹é«”é›»è¦–å°ç›®éŒ„.txt')
          extract('swepg.xml', 'ç®€ä½“ç”µè§†å°ç›®å½•.txt')
          EOF

      - name: Commit and push results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # åŠ å…¥ README.md åˆ°æäº¤åˆ—è¡¨
          git add "ç¹é«”é›»è¦–å°ç›®éŒ„.txt" "ç®€ä½“ç”µè§†å°ç›®å½•.txt" "*.json" "README.md"
          
          if git diff --cached --quiet; then
            echo "âš ï¸ æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´"
          else
            git commit -m "Update EPG analysis and README (auto-generated)"
            for i in {1..3}; do
              if git push; then
                echo "âœ… æäº¤å¹¶æ¨é€æˆåŠŸ"; exit 0
              else
                git pull --rebase
              fi
            done
            exit 1
          fi
