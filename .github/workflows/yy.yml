name: æå–é›»è¦–å°åç¨±å’Œç”Ÿæˆåˆ†æå ±å‘Šçµ±è¨ˆè¡¨æ¸¬è©¦çµ‚æ¥µç‰ˆ
on:
  schedule:
    - cron: '45 */6 * * *'
  workflow_dispatch:

jobs:
  extract:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout current repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download XML files
        run: |
          curl -L --retry 3 --max-time 10 -o twepg.xml https://raw.githubusercontent.com/zzq1234567890/epg/main/twepg.xml
          curl -L --retry 3 --max-time 10 -o swepg.xml https://raw.githubusercontent.com/zzq1234567890/epg/main/swepg.xml
          [ -s twepg.xml ] || { echo "twepg.xml ä¸ºç©º"; exit 1; }
          [ -s swepg.xml ] || { echo "swepg.xml ä¸ºç©º"; exit 1; }

      - name: Extract channel names, analyze, and update README
        run: |
          python <<'EOF'
          import xml.etree.ElementTree as ET
          import json
          from datetime import datetime
          import re
          import os

          def analyze_epg_data(xml_file):
              try:
                  tree = ET.parse(xml_file)
                  root = tree.getroot()
                  ns = {}
                  if root.tag.startswith('{'):
                      ns_uri = root.tag.split('}')[0][1:]
                      ns = {'ns': ns_uri}
                  
                  channels_info = {}
                  channel_xpath = 'ns:channel' if ns else 'channel'
                  
                  for channel in root.findall(channel_xpath, ns):
                      channel_id = channel.get('id')
                      if not channel_id: continue
                      
                      name = channel.get('display-name')
                      if not name:
                          name_elem = channel.find('ns:display-name' if ns else 'display-name', ns)
                          name = name_elem.text.strip() if name_elem is not None and name_elem.text else None
                      
                      name = name.strip() if name else channel_id
                      channels_info[channel_id] = {
                          'name': name,
                          'program_count': 0,
                          'start_times': [],
                          'end_times': []
                      }

                  programme_xpath = 'ns:programme' if ns else 'programme'
                  for programme in root.findall(programme_xpath, ns):
                      channel_id = programme.get('channel')
                      if channel_id not in channels_info: continue
                          
                      channels_info[channel_id]['program_count'] += 1
                      start = programme.get('start')
                      stop = programme.get('stop')
                      
                      if start: channels_info[channel_id]['start_times'].append(re.sub(r'\s+[+-]\d{4}$', '', start))
                      if stop: channels_info[channel_id]['end_times'].append(re.sub(r'\s+[+-]\d{4}$', '', stop))

                  result = []
                  for channel_id, info in channels_info.items():
                      time_range = "ç„¡æ•¸æ“š"
                      duration_days = 0
                      epg_status = "â–¡"
                      
                      if info['start_times'] and info['end_times']:
                          try:
                              sorted_starts = sorted(info['start_times'])
                              sorted_ends = sorted(info['end_times'])
                              start_dt = datetime.strptime(sorted_starts[0], '%Y%m%d%H%M%S')
                              end_dt = datetime.strptime(sorted_ends[-1], '%Y%m%d%H%M%S')
                              
                              delta = end_dt - start_dt
                              duration_days = delta.days + (1 if delta.seconds > 0 else 0)
                              
                              time_range = f"{start_dt.strftime('%m-%d %H:%M')} ~ {end_dt.strftime('%m-%d %H:%M')}"
                          except:
                              time_range = "æ ¼å¼ç•°å¸¸"

                      if info['program_count'] > 0: epg_status = "â– "

                      result.append({
                          'channel_id': channel_id,
                          'channel_name': info['name'],
                          'program_count': info['program_count'],
                          'duration_days': duration_days,
                          'time_range': time_range,
                          'epg_status': epg_status
                      })
                  
                  result.sort(key=lambda x: x['channel_name'].lower())
                  return result
              except Exception as e:
                  print(f"âŒ è§£æ {xml_file} å‡ºéŒ¯: {e}")
                  return []

          print("æ­£åœ¨åˆ†æ EPG æ•¸æ“š...")
          tw_data = analyze_epg_data('twepg.xml')
          sw_data = analyze_epg_data('swepg.xml')

          # --- ç”Ÿæˆ JSON æ–‡ä»¶ (ä¿æŒåŸæœ‰åŠŸèƒ½) ---
          def generate_files(data, prefix):
              table_data = {
                  'title': f'{prefix}åˆ—è¡¨',
                  'headers': ['é¢‘é“ID', 'é¢‘é“åç§°', 'èŠ‚ç›®æ•°é‡', 'å¤©æ•°', 'æ—¶é—´èŒƒå›´', 'çŠ¶æ€'],
                  'data': [[c['channel_id'], c['channel_name'], c['program_count'], c['duration_days'], c['time_range'], c['epg_status']] for c in data]
              }
              with open(f'{prefix}_channels_table.json', 'w', encoding='utf-8') as f:
                  json.dump(table_data, f, ensure_ascii=False, indent=2)

          generate_files(tw_data, 'traditional')
          generate_files(sw_data, 'simplified')

          # --- ç”Ÿæˆ README.md ---
          def generate_readme():
              
              USER_CUSTOM_INTRO = """
# ğŸ“º EPG é›»å­ç¯€ç›®è¡¨ç‹€æ…‹å ±å‘Š

æœ¬EPGèªªæ˜:

æ³¨æ„:

1. è‡ªå¨›è‡ªæ¨‚ï¼è‡ªç”¨ï¼Œè«‹å‹¿ç”¨ä½œå•†æ¥­ç”¨é€”ï¼ä¸€èˆ¬ä¸é€²è¡Œç¶­è­·å’ŒæŠ€è¡“æ”¯æŒï¼

æ¨è–¦æ’­æ”¾è»Ÿé«” okå½±è¦–ï¼Œ Tivimate, ott navigator,æ¥µè‡´æ’­æ”¾å™¨ï¼epgé¸æ“‡xml.gzæ ¼å¼ã€‚é€Ÿåº¦å¿«ï¼Œé«”ç©å°ã€‚

2. ä¸æä¾›ç¯€ç›®æºåœ°å€ï¼è«‹æ”¯æŒè¨‚é–±æ­£ç‰ˆç¯€ç›®æºåœ°å€ï¼

3. Youtubeåƒ…åƒ…æä¾›åœ°å€ï¼Œä¸å¸¶ä»»ä½•è§£æã€‚å»ºè­°ç”¨å½±è¦–(å½±è¦–ç›´æ’­å°xmlæ”¯æŒè¼ƒå·®)ã€‚

4. å¢»å…§å»ºè­°é¸epgnew.xml(å»æ‰å¹¾å€‹å°‘å…’ä¸å®œåŠå°å²¸ç¦æ­¢çš„å¹¾å€‹é›»è¦–å°é å‘Š)ï¼Œå¢»å¤–ç„¡æ‰€è¬‚äº†ï¼Œepgziyong.xmlé‚„æ˜¯epgnew.xmléš¨ä¾¿äº†

5. æœ¬ç¯€ç›®é å‘ŠåŒ…æ‹¬

ä¸­åœ‹å¤§é™¸

å¤®è¦–é » 1905 æµ™æ±Ÿ æ±Ÿè˜‡ æ²³åŒ— åŒ—äº¬ ä¸Šæµ· é‡æ…¶ ç¦å»º å»£æ± å»£è¥¿ æ±Ÿè˜‡ æ±Ÿè¥¿ å››å· å…§è’™å¤ æ–°ç–†

é¦™æ¸¯
mytvsuper anywhere tvb anywhere usa nowå¯¬é » hoyé›»è¦–å° é¦™æ¸¯é›»å°ï¼Œ

æ¾³é–€ æ¾³é–€é›»è¦–å°

å°ç£ mod bbå¯¬é » tbcæœ‰ç·š 4gtv hami ofiii

éŸ“åœ‹ kbs sbs mbc ebc

æ–°åŠ å¡ mewatch

é¦¬ä¾†è¥¿äº astro å°å°¼ epgmncvision

6. å¢åŠ  ç°¡é«”ç‰ˆæœ¬çš„epgï¼Œé©åˆä¸­åœ‹å¤§é™¸ï¼Œæ–°åŠ å¡ï¼Œé©¬æ¥è¥¿äºšï¼Œswepg.xml.gzï¼Œ(ç¶²å€: https://github.com/zzq1234567890/epg/raw/refs/heads/main/swepg.xml.gz );
ç¹é«”ç‰ˆæœ¬epg,é©åˆé¦™æ¸¯æ¾³é–€å°ç£ï¼Œtwepg.xml.gz. ï¼ˆç¶²å€: https://github.com/zzq1234567890/epg/raw/refs/heads/main/twepg.xml.gz );

7. å¼·çƒˆæ¨è–¦xm.gz,è€Œä¸æ˜¯xmlæ ¼å¼ï¼Œæª”æ¡ˆå°å¾ˆå¤š

å…·é«”é›»è¦–å°åç¨±åƒè¦‹

ç¹é«”[https://raw.githubusercontent.com/zzq1234567890/epg/refs/heads/main/ç¹é«”é›»è¦–å°ç›®éŒ„.txt];

ç°¡é«”é›»è¦–å°ç›®éŒ„[ https://raw.githubusercontent.com/zzq1234567890/epg/refs/heads/main/ç®€ä½“ç”µè§†å°ç›®å½•.txt]

ä¸»è¦æ˜¯å¡«å¯« tvg-id="ç”µè§†å°åç§°" tvg-name="ç”µè§†å°åç§°"

ç¹é«”ï¼Œé©åˆæ¸¯æ¾³å° #EXTM3U url-tvg="https://github.com/zzq1234567890/epg/raw/refs/heads/main/swepg.xml.gz" catchup="append" catchup-source="?playseek=${(b)yyyyMMddHHmmss}-${(e)yyyyMMddHHmmss}"

#EXTINF:-1 tvg-id="é›»è¦–å°åç¨±" tvg-name="é›»è¦–å°åç¨±" tvg-logo="https://epg.51/tb1/CCTV/CCTV1.png" group-title="ä½ çš„åˆ†ç»„",ç”µè§†å°åç§°

ç¯€ç›®åœ°å€

ç°¡é«”ï¼Œé©åˆæ±å—äºåŠä¸­åœ‹å¤§é™¸ç”¨ å…·é«”æ ¼å¼

#EXTM3U url-tvg="https://github.com/zzq1234567890/epg/raw/refs/heads/main/swepg.xml.gz" catchup="append" catchup-source="?playseek=${(b)yyyyMMddHHmmss}-${(e)yyyyMMddHHmmss}"

#EXTINF:-1 tvg-id="ç”µè§†å°åç§°" tvg-name="ç”µè§†å°åç§°" tvg-logo="https://epg.51/tb1/CCTV/CCTV1.png" group-title="ä½ çš„åˆ†ç»„",ç”µè§†å°åç§° ç¯€ç›®æºåœ°å€

---
## Important Notices

1. For Personal Use Only â€“ Commercial Use Strictly Prohibited This service is exclusively intended for personal entertainment and non-commercial use. Maintenance and technical support are not provided as a general policy. Recommended Playback Applications: Tivimate, OTT Navigator, Jizhi Player.

2. No Program Source URLs Distributed We do not provide or share program source URLs. Please support legitimate content by subscribing to official program source URLs.

3. YouTube URLs Provided â€œAs-Isâ€ (No Parsing Functionality) YouTube URLs are shared in their raw format without any parsing, decoding, or technical processing. For optimal compatibility, we recommend using Yingshi (Note: Yingshi Live has limited support for XML formats).

4. Adding the epg of some chinese local channels from guangxi tv website.

5. Adding the epg of local tv channels of hebei&guangdong province .

6. Adding the epg of some HOY new channels

7. Adding the epg of six channels from TVB anywhere USA .

8. Adding the epg for simplied chinese ,swepg.xml.gz, used in mainland of china; the epg of tradional chinese epg,tw.epg.gz, used in hk ,marcol,taiwan area .

---
"""

              current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
              
              # 1. æ’å…¥è‡ªå®šç¾©é–‹é ­æ–‡å­—
              md_content = USER_CUSTOM_INTRO.strip() + "\n\n"
              
              # 2. æ’å…¥è‡ªå‹•ç”Ÿæˆçš„å ±å‘Šå…§å®¹
              md_content += f"## ğŸ“Š æ•¸æ“šåˆ†æèˆ‡ç‹€æ…‹å ±å‘Š\n\n"
              md_content += f"> **æœ€å¾Œæ›´æ–°æ™‚é–“**: **{current_time}**\n\n"
              md_content += f"### æ‘˜è¦\n"
              md_content += f"- **ç¹é«”é »é“æ•¸**: {len(tw_data)} (ç¯€ç›®ç¸½æ•¸: {sum(x['program_count'] for x in tw_data)})\n"
              md_content += f"- **ç°¡é«”é »é“æ•¸**: {len(sw_data)} (ç¯€ç›®ç¸½æ•¸: {sum(x['program_count'] for x in sw_data)})\n\n"

              for title, data in [("ğŸ‡¹ğŸ‡¼ ç¹é«”é »é“åˆ—è¡¨", tw_data), ("ğŸ‡¨ğŸ‡³ ç°¡é«”é »é“åˆ—è¡¨", sw_data)]:
                  md_content += f"### {title}\n\n"
                  md_content += "| é »é“åç¨± | ç¯€ç›®æ•¸é‡ | è¦†è“‹å¤©æ•¸ | æ™‚é–“ç¯„åœ | ç‹€æ…‹ |\n"
                  md_content += "| :--- | :---: | :---: | :--- | :---: |\n"
                  
                  for item in data:
                      status_icon = "âœ…" if item['epg_status'] == "â– " else "âš ï¸"
                      count_display = item['program_count'] if item['program_count'] > 0 else "**0**"
                      
                      row = f"| {item['channel_name']} | {count_display} | {item['duration_days']} å¤© | {item['time_range']} | {status_icon} |\n"
                      md_content += row
                  md_content += "\n"
              
              with open('README.md', 'w', encoding='utf-8') as f:
                  f.write(md_content)
              print("âœ… README.md å·²æ›´æ–°")

          generate_readme()
          EOF

      - name: Extract channel names (ä¿æŒé¡ºåº)
        run: |
          python <<'EOF'
          import xml.etree.ElementTree as ET
          def extract(xml, out):
              try:
                  tree = ET.parse(xml)
                  root = tree.getroot()
                  ns = {'ns': root.tag.split('}')[0][1:]} if root.tag.startswith('{') else {}
                  seen = set()
                  lines = []
                  path = 'ns:channel' if ns else 'channel'
                  for c in root.findall(path, ns):
                      n = c.get('display-name')
                      if not n:
                          ne = c.find('ns:display-name' if ns else 'display-name', ns)
                          n = ne.text.strip() if ne and ne.text else c.get('id')
                      if n and n not in seen:
                          seen.add(n); lines.append(n)
                  with open(out, 'w', encoding='utf-8') as f: f.write('\n'.join(lines))
              except: pass
          extract('twepg.xml', 'ç¹é«”é›»è¦–å°ç›®éŒ„.txt')
          extract('swepg.xml', 'ç®€ä½“ç”µè§†å°ç›®å½•.txt')
          EOF

      - name: Commit and push results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add "ç¹é«”é›»è¦–å°ç›®éŒ„.txt" "ç®€ä½“ç”µè§†å°ç›®å½•.txt" "*.json" "README.md"
          
          if git diff --cached --quiet; then
            echo "âš ï¸ æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´"
          else
            git commit -m "Update EPG analysis and README (auto-generated)"
            for i in {1..3}; do
              if git push; then
                echo "âœ… æäº¤å¹¶æ¨é€æˆåŠŸ"; exit 0
              else
                git pull --rebase
              fi
            done
            exit 1
          fi
